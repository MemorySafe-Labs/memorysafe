# Memory Vulnerability Index (MVI)  
**Predictive Forgetting Risk Scoring for Intelligent Replay Buffer Management in Continual Learning**

**MemorySafe Labs**  
Carla Centeno, Founder  
February 2026  
https://memorysafe.ca | NVIDIA Inception Program Member

## License & IP Notice
This document describes the conceptual foundation of the Memory Vulnerability Index (MVI), a core component of the MemorySafe system.  
All rights reserved. This is proprietary technology developed by MemorySafe Labs. No part of this method may be reproduced, adapted, or used commercially without explicit written permission. For collaboration, licensing, or inquiries: carla@memorysafe.ca.

## 1. The Problem: Catastrophic Forgetting in Continual Learning
In continual (lifelong) learning, models must learn from non-stationary data streams without access to the full past dataset. Replay buffers help mitigate **catastrophic forgetting** by storing and replaying a small subset of previous experiences.

Standard replay methods (reservoir sampling, FIFO, uncertainty/hard-example mining) treat buffer samples mostly equally or use simple heuristics. This leads to:
- Disproportionate forgetting of **rare or safety-critical experiences** (e.g., anomalies, minority classes in medical imaging, unusual obstacles in robotics).
- Inefficient buffer usage under fixed memory constraints (especially on edge devices like Jetson).
- No proactive prediction of which samples are at highest risk of being forgotten **before** degradation occurs.

## 2. Memory Vulnerability Index (MVI) — Core Idea
MVI is a **predictive, per-sample forgetting risk score** (scalar ∈ [0, 1]) that quantifies **how vulnerable a stored experience is to catastrophic forgetting** if not replayed or protected soon.

Instead of reactive or uniform buffer management, MVI enables **proactive, risk-aware governance**:
- High-MVI samples → prioritize for protection / forced replay / harder eviction.
- Low-MVI samples → safe candidates for eviction when buffer is full.

This turns the replay buffer into an **intelligent, predictive cache** rather than a dumb FIFO or random sampler.

## 3. High-Level Signals Combined into MVI
MVI aggregates multiple complementary signals, each grounded in established continual learning research on forgetting mechanisms:

- **Forgetting Velocity**  
  Rate of performance degradation on this sample since last replay (e.g., change in prediction confidence, loss increase, or gradient magnitude during recent updates).

- **Feature / Representation Drift**  
  Shift between the sample's current embedding and the model's evolving feature space (e.g., distance in latent space).

- **Rarity & Imbalance Signal**  
  Inverse frequency of the sample's class/pseudo-class in recent stream + buffer (boosts minority / rare events).

- **Temporal / Task Age Decay**  
  How long ago the sample was collected (exponential decay — older experiences are generally more at risk).

These signals are normalized and combined into a single MVI score.  
**Exact combination weights, normalization functions, and update frequency are proprietary tuning parameters of MemorySafe.**

## 4. How MVI is Used in MemorySafe
During training (after each task / minibatch / periodically):
1. Compute MVI for all buffer samples.
2. Apply **ProtectScore policy** → high-MVI samples are protected (e.g., eviction priority lowered, forced inclusion in replay batches).
3. When buffer is full → evict lowest-MVI samples first.

Result: **Intelligent rarity enrichment** and protection of vulnerable experiences without over-protecting majority classes.

## 5. Empirical Validation (High-Level Results)
Evaluated on standard continual learning benchmarks (multi-seed averages):

- **PneumoniaMNIST** (imbalanced binary medical classification)  
  → Achieved **perfect rare-class recall (1.000)** across seeds.  
  → Buffer positive fraction enriched to ~0.11–0.12 (vs. ~2% in stream).  
  → Specificity remained strong (0.004–0.012 in best configs) — no majority collapse.

- **CIFAR-100 Class-Incremental** (5 tasks × 20 classes, ResNet-18)  
  → Final incremental accuracy: ~53.17% (10-seed avg).  
  → +8.2% relative over standard reservoir replay.  
  → ~18% reduction in forgetting vs. plain replay.  
  → Low variance across seeds.

- Memory efficiency gains demonstrated via downsampling + feature replay → 81–99% realistic savings.

These results show MVI enables strong rare-event protection while preserving overall performance.

## 6. Applications & Why It Matters
MVI is particularly valuable for **safety-critical, edge-constrained domains**:
- Medical AI (rare pathology detection on ultrasound/X-ray devices)
- Robotics (anomaly / failure / obstacle handling in dynamic environments)
- Industrial monitoring (rare fault detection)
- Any low-memory continual system where forgetting rare events is unacceptable.

## 7. Limitations & Future Directions
- Current validation focused on image-based continual learning benchmarks.
- Transfer to sequential/time-series robotics data (proprioception, video, actions) requires domain-specific adaptations (e.g., trajectory-level rarity, state-action signals).
- Ongoing work: hybrid combinations (MVI + distillation), on-device implementations (Jetson), real robotics pilots.

For more information, licensing discussions, or collaboration:  
**Carla Centeno** — carla@memorysafe.ca  
MemorySafe Labs — https://memorysafe.ca

© 2026 MemorySafe Labs. All rights reserved.
